{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRTECAN Module Deep Dive Tutorial\n",
    "\n",
    "This tutorial explores the `prtecan` module for processing Tecan plate reader data with a focus on:\n",
    "- File parsing and data structures\n",
    "- Titration curve analysis\n",
    "- Advanced fitting capabilities\n",
    "- Visualization techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Magic commands for development\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "    \n",
    "# Setup\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from clophfit import prtecan\n",
    "\n",
    "# Configure notebook\n",
    "%matplotlib inline\n",
    "plt.style.use(\"seaborn-v0_8\")\n",
    "data_dir = Path(\"../../tests/Tecan/140220\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Core Data Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 Labelblock - Fundamental data unit\n",
    "file_path = data_dir / \"pH6.5_200214.xls\"\n",
    "csvl = prtecan.read_xls(file_path)\n",
    "idxs = prtecan.lookup_listoflines(csvl)\n",
    "lb = prtecan.Labelblock(csvl[idxs[0] : idxs[1]], str(file_path))\n",
    "\n",
    "print(\"--- Labelblock Metadata ---\")\n",
    "for k, v in lb.metadata.items():\n",
    "    print(f\"{k}: {v.value}\")\n",
    "\n",
    "print(\"\\nSample Data (A01-H12):\")\n",
    "print({k: v for i, (k, v) in enumerate(lb.data.items()) if i < 12})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. File Processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 Complete processing workflow\n",
    "tit = prtecan.Titration.fromlistfile(data_dir / \"list.pH.csv\", is_ph=True)\n",
    "tit.load_scheme(data_dir / \"scheme.txt\")\n",
    "tit.load_additions(data_dir / \"additions.pH\")\n",
    "\n",
    "print(\n",
    "    f\"Titration with {len(tit.tecanfiles)} files and {len(tit.labelblocksgroups)} label groups\"\n",
    ")\n",
    "print(f\"Buffer wells: {tit.scheme.buffer}\")\n",
    "print(f\"pH range: {tit.x.min():.1f} to {tit.x.max():.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Analysis Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 Accessing processed data\n",
    "well = \"D10\"\n",
    "data = {\n",
    "    \"pH\": tit.x,\n",
    "    \"Signal (raw)\": tit.labelblocksgroups[1].data_nrm[well],\n",
    "    \"Signal (processed)\": tit.data[1][well],\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(data[\"pH\"], data[\"Signal (raw)\"], \"o-\", label=\"Raw\")\n",
    "plt.plot(data[\"pH\"], data[\"Signal (processed)\"], \"s-\", label=\"Processed\")\n",
    "plt.xlabel(\"pH\")\n",
    "plt.ylabel(\"Fluorescence\")\n",
    "plt.title(f\"Data Processing Pipeline for Well {well}\")\n",
    "plt.legend()\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fitting Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 Comparing fitting methods\n",
    "tit.params.bg = True\n",
    "tit.params.dil = True\n",
    "tit.params.nrm = True\n",
    "\n",
    "# Run all fitting methods\n",
    "result_single = tit.results[1][well]\n",
    "result_global = tit.result_global[well]\n",
    "result_odr = tit.result_odr[well]\n",
    "\n",
    "print(\n",
    "    f\"Single fit Kd: {result_single.result.params['K'].value:.2f} ± {result_single.result.params['K'].stderr:.2f}\"\n",
    ")\n",
    "print(\n",
    "    f\"Global fit Kd: {result_global.result.params['K'].value:.2f} ± {result_global.result.params['K'].stderr:.2f}\"\n",
    ")\n",
    "print(\n",
    "    f\"ODR fit Kd: {result_odr.result.params['K'].value:.2f} ± {result_odr.result.params['K'].stderr:.2f}\"\n",
    ")\n",
    "\n",
    "plt.figure()\n",
    "result_single.figure\n",
    "plt.figure\n",
    "result_global.figure.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"../../tests/Tecan/140220\")\n",
    "data_dir = Path(\"/home/dati/arslanbaeva/data/raw/L2/\")\n",
    "\n",
    "tit = prtecan.Titration.fromlistfile(data_dir / \"list.pH.csv\", is_ph=1)\n",
    "tit.load_additions(data_dir / \"additions.pH\")\n",
    "tit.load_scheme(data_dir / \"scheme.txt\")\n",
    "tit.params.bg_mth = \"meansd\"\n",
    "tit.bg_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tit.result_global.compute_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tit.result_global.plot_k()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_fr(fr):\n",
    "    print(fr.result.redchi)\n",
    "    print(fr.dataset)\n",
    "    return fr.figure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clophfit.binding.fitting import fit_binding_glob, fit_binding_glob_recursive, fit_binding_glob_recursive_outlier, fit_binding_glob_reweighted, outlier2\n",
    "from clophfit.binding.fitting import DataArray, Dataset, weight_da, weight_multi_ds_titration, outlier_glob, fit_binding_pymc, fit_binding_pymc2, fit_binding_pymc_compare\n",
    "import arviz as az"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = \"A01\"\n",
    "\n",
    "ds = tit._create_global_ds(k)\n",
    "ds[\"y1\"].y_err.mean(), ds[\"y2\"].y_err.mean()\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_binding_glob(ds).figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[\"y1\"].y_errc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr = outlier2(ds, k, plot_z_scores=1, threshold=3.0)\n",
    "fr.figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr.result.logger = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fr.result.redchi)\n",
    "print(fr.result.chisqr)\n",
    "fr.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds2 = tit._create_ds(k, 2)\n",
    "ds2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_binding_glob(ds2).figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = \"A01\"\n",
    "fr = tit.result_global[k]\n",
    "fr.figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\"y1\": tit.bg_err[1].mean(), \"y2\": tit.bg_err[2].mean()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sd = 0.15 / fr.result.params[\"K\"].stderr\n",
    "print(n_sd)\n",
    "\n",
    "# Run the model with a single noise scaling factor\n",
    "#trace_single = fit_binding_pymc_compare(fr, n_sd=max(n_sd,1), n_xerr=.682, learn_separate_y_mag=False)\n",
    "\n",
    "# Run the model with separate noise scaling factors for each label\n",
    "#trace_separate_shot = fit_binding_pymc_compare(fr, n_sd=max(n_sd,1), n_xerr=.682, learn_separate_y_mag=True)\n",
    "trace_separate_shot = fit_binding_pymc_compare(fr, {\"y1\": tit.bg_err[1].mean(), \"y2\": tit.bg_err[2].mean()}, n_sd=max(n_sd,1), n_xerr=.682, learn_separate_y_mag=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(trace_separate_shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(trace_single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(trace_separate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can pass the traces directly to az.compare\n",
    "comparison_results = az.compare({\"single_y_mag\": trace_separate_shot, \"separate_y_mag\": trace_separate})\n",
    "\n",
    "# The result is a pandas DataFrame.\n",
    "# The best model has the lowest 'loo' or 'waic' value.\n",
    "# The 'd_loo' column shows the difference from the best model.\n",
    "comparison_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sd = 0.15 / fr.result.params[\"K\"].stderr\n",
    "print(n_sd)\n",
    "fr_mcmc2 = fit_binding_pymc(fr, n_sd=max(n_sd,1), n_xerr=.682)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "df = az.summary(fr_mcmc2.mini)\n",
    "fr_mcmc2.figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "az.summary(fr_mcmc.mini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da1.mask = ~outlier_glob(fr.result.residual, plot_z_scores=1, threshold=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_fr(fit_binding_glob_reweighted(ds, k, threshold=2.25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Advanced Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1 Bayesian fitting with PyMC\n",
    "tit.params.mcmc = \"single\"\n",
    "result_mcmc = tit.result_mcmc[well]\n",
    "\n",
    "print(\"MCMC Results:\")\n",
    "print(f\"Kd: {result_mcmc.result.params['K'].value:.2f}\")\n",
    "print(\n",
    "    f\"95% HDI: [{result_mcmc.result.params['K'].min:.2f}, {result_mcmc.result.params['K'].max:.2f}]\"\n",
    ")\n",
    "\n",
    "# Plot trace\n",
    "import arviz as az\n",
    "\n",
    "az.plot_trace(result_mcmc.mini, var_names=[\"K\", \"x_true\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 6. Quality Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.1 Buffer analysis\n",
    "buffer_plot = tit.buffer.plot(nrm=True, title=\"Buffer Consistency Check\")\n",
    "plt.show()\n",
    "\n",
    "# 6.2 Temperature monitoring\n",
    "temp_plot = tit.plot_temperature()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 7. Batch Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.1 Export all results\n",
    "from tempfile import mkdtemp\n",
    "\n",
    "output_dir = Path(mkdtemp())\n",
    "\n",
    "config = prtecan.TecanConfig(\n",
    "    out_fp=output_dir, comb=True, lim=None, title=\"FullAnalysis\", fit=True, png=True\n",
    ")\n",
    "tit.export_data_fit(config)\n",
    "\n",
    "print(f\"Exported to: {output_dir}\")\n",
    "print(\"Contents:\", *[f.name for f in output_dir.glob(\"*\")], sep=\"\\n- \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Titration Construction\n",
    "\n",
    "### Handling Files with Non-Identical Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load files with different metadata\n",
    "files = [\n",
    "    data_dir / \"pH6.5_200214.xls\",  # Different gain settings\n",
    "    data_dir / \"pH7.08_200214.xls\",\n",
    "]\n",
    "\n",
    "# Create titration with pH values\n",
    "mixed_tit = prtecan.Titration(\n",
    "    [prtecan.Tecanfile(f) for f in files], x=np.array([6.5, 7.08]), is_ph=True\n",
    ")\n",
    "\n",
    "# Show metadata differences\n",
    "print(\"Metadata Comparison:\")\n",
    "for i, tf in enumerate(mixed_tit.tecanfiles):\n",
    "    print(\n",
    "        f\"File {i + 1} - Gain:\",\n",
    "        tf.labelblocks[1].metadata[\"Gain\"].value,\n",
    "        tf.labelblocks[1].metadata[\"Gain\"].unit,\n",
    "    )\n",
    "\n",
    "# Verify normalization worked\n",
    "well = \"D10\"\n",
    "print(f\"\\nNormalized values for {well}:\")\n",
    "print(\"File 1:\", mixed_tit.labelblocksgroups[1].data_nrm[well][0])\n",
    "print(\"File 2:\", mixed_tit.labelblocksgroups[1].data_nrm[well][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background Calculation Methods Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_tit = tit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure experiment\n",
    "mixed_tit.load_scheme(data_dir / \"scheme.txt\")\n",
    "mixed_tit.load_additions(data_dir / \"additions.pH\")\n",
    "\n",
    "# Test different background methods\n",
    "methods = [\"mean\", \"meansd\", \"fit\"]\n",
    "results = {}\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "for i, method in enumerate(methods, 1):\n",
    "    # Set calculation method\n",
    "    mixed_tit.params.bg_mth = method\n",
    "\n",
    "    # Store results\n",
    "    results[method] = {\"bg\": mixed_tit.bg[1][0], \"processed\": mixed_tit.data[1][well]}\n",
    "\n",
    "    # Plot\n",
    "    plt.subplot(1, 3, i)\n",
    "    plt.plot(mixed_tit.x, mixed_tit.data[1][well], \"o-\", label=method)\n",
    "    plt.axhline(y=0, color=\"gray\", linestyle=\"--\")\n",
    "    plt.title(f\"Method: {method}\")\n",
    "    plt.xlabel(\"pH\")\n",
    "    plt.ylabel(\"Signal\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show numerical comparison\n",
    "print(\"Background Values:\")\n",
    "for method, vals in results.items():\n",
    "    print(f\"{method}: {vals['bg']:.1f}\")\n",
    "\n",
    "print(\"\\nFirst Point Values:\")\n",
    "for method, vals in results.items():\n",
    "    print(f\"{method}: {vals['processed'][0]:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buffer Analysis Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize buffer fits for each method\n",
    "plt.figure(figsize=(18, 5))\n",
    "\n",
    "for i, method in enumerate(methods, 1):\n",
    "    mixed_tit.params.bg_mth = method\n",
    "\n",
    "    plt.subplot(1, 3, i)\n",
    "    df = mixed_tit.buffer.dataframes_nrm[1]\n",
    "\n",
    "    # Plot raw buffer data\n",
    "    for col in df.columns:\n",
    "        if col not in [\"fit\", \"fit_err\", \"mean\", \"sem\", \"Label\"]:\n",
    "            plt.plot(mixed_tit.x, df[col], \"o\", alpha=0.3)\n",
    "\n",
    "    # Plot fit results\n",
    "    plt.plot(mixed_tit.x, df[\"fit\"], \"r-\", lw=2, label=\"Fit\")\n",
    "    plt.fill_between(\n",
    "        mixed_tit.x,\n",
    "        df[\"fit\"] - df[\"fit_err\"],\n",
    "        df[\"fit\"] + df[\"fit_err\"],\n",
    "        color=\"r\",\n",
    "        alpha=0.2,\n",
    "    )\n",
    "\n",
    "    plt.title(f\"Buffer {method} method\")\n",
    "    plt.xlabel(\"pH\")\n",
    "    plt.ylabel(\"Signal\")\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Observations\n",
    "\n",
    "1. **Metadata Handling**:\n",
    "   - Files with different instrument settings (like gain) can be merged after normalization\n",
    "   - The module automatically handles unit conversions and scaling\n",
    "\n",
    "2. **Background Methods**:\n",
    "   - `mean`: Simple average of buffer wells\n",
    "   - `meansd`: More conservative estimate using mean ± 1SD\n",
    "   - `fit`: Linear regression of buffer wells vs. pH\n",
    "\n",
    "3. **Impact on Results**:\n",
    "   - Different methods can significantly affect baseline correction\n",
    "   - The fitting method accounts for pH-dependent buffer effects\n",
    "   - More conservative methods may preserve signal dynamics better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Modular Architecture**: The `prtecan` module processes data through well-defined stages\n",
    "2. **Reproducible Workflows**: All processing steps are traceable and configurable\n",
    "3. **Advanced Fitting**: Multiple fitting methods with automatic error propagation\n",
    "4. **Quality Control**: Built-in tools for monitoring experimental conditions\n",
    "5. **Scalability**: Handles both single experiments and high-throughput screens"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
