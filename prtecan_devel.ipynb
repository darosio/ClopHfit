{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Tips for development vs tutorial hygiene:\n",
    "---\n",
    "- Keep a scratch notebook (e.g., `prtecan_devel.ipynb`) for experiments.\n",
    "- Avoid `os.chdir`; use Path objects relative to repository root as in this notebook.\n",
    "- When a feature stabilizes, port minimal, clear examples into the main tutorial and keep heavy testing in `tests/`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Magic commands for development\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "from clophfit import prtecan\n",
    "from clophfit.fitting.bayes import (\n",
    "    fit_binding_pymc,\n",
    "    fit_binding_pymc2,\n",
    "    fit_binding_pymc_compare,\n",
    ")\n",
    "from clophfit.fitting.core import (\n",
    "    fit_binding_glob,\n",
    "    fit_binding_glob_recursive,\n",
    "    fit_binding_glob_recursive_outlier,\n",
    "    fit_binding_glob_reweighted,\n",
    "    outlier2,\n",
    ")\n",
    "from clophfit.fitting.odr import (\n",
    "    fit_binding_odr,\n",
    "    fit_binding_odr_recursive,\n",
    "    fit_binding_odr_recursive_outlier,\n",
    ")\n",
    "\n",
    "# Configure notebook\n",
    "%matplotlib inline\n",
    "plt.style.use(\"seaborn-v0_8\")\n",
    "\n",
    "data_root = Path(\"tests/Tecan\")\n",
    "l0_dir = data_root / \"140220\"\n",
    "l1_dir = data_root / \"L1\"\n",
    "l2_dir = data_root / \"L2\"\n",
    "l4_dir = data_root / \"L4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tit(folder, bg_mth=\"meansd\"):\n",
    "    tit = prtecan.Titration.fromlistfile(folder / \"list.pH.csv\", is_ph=1)\n",
    "    tit.load_additions(folder / \"additions.pH\")\n",
    "    tit.load_scheme(folder / \"scheme.txt\")\n",
    "    tit.params.bg_mth = bg_mth\n",
    "    tit.params.bg_adj = True\n",
    "    return tit\n",
    "\n",
    "\n",
    "tit = tit(l2_dir)\n",
    "tit.bg_err"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from clophfit.fitting.core import fit_binding_pymc_multi2\n",
    "\n",
    "trace = fit_binding_pymc_multi2(\n",
    "    tit.result_global.results, tit.scheme, tit.buffer.bg_err\n",
    ")\n",
    "\n",
    "df = az.summary(trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## residual cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tit.result_global.compute_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from clophfit.fitting.core import FitResult\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ResidualPoint:\n",
    "    \"\"\"For single points.\"\"\"\n",
    "\n",
    "    label: str\n",
    "    x: float\n",
    "    resid_weighted: float  # lmfit residual = (y - model) / y_err\n",
    "    resid_raw: float  # (y - model)\n",
    "    i: int  # index within that label (after masking)\n",
    "\n",
    "\n",
    "def residual_points(fr: FitResult) -> list[ResidualPoint]:\n",
    "    if fr.result is None or fr.dataset is None:\n",
    "        return []\n",
    "    r = np.asarray(fr.result.residual, float)\n",
    "    pts: list[ResidualPoint] = []\n",
    "\n",
    "    start = 0\n",
    "    for lbl, da in fr.dataset.items():\n",
    "        n = len(da.y)  # masked length\n",
    "        rw = r[start : start + n]\n",
    "        rr = rw * da.y_err  # undo weighting (since rw = (y-model)/y_err)\n",
    "        xs = da.x\n",
    "        pts.extend(\n",
    "            ResidualPoint(\n",
    "                label=lbl,\n",
    "                x=float(xs[i]),\n",
    "                resid_weighted=float(rw[i]),\n",
    "                resid_raw=float(rr[i]),\n",
    "                i=i,\n",
    "            )\n",
    "            for i in range(n)\n",
    "        )\n",
    "        start += n\n",
    "    if start != len(r):\n",
    "        msg = f\"Residual length mismatch: consumed {start}, residual has {len(r)}\"\n",
    "        raise ValueError(msg)\n",
    "    return pts\n",
    "\n",
    "\n",
    "def residual_frame(fr: FitResult) -> pd.DataFrame:\n",
    "    return pd.DataFrame([p.__dict__ for p in residual_points(fr)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_res = pd.DataFrame()\n",
    "for k in tit.fit_keys:\n",
    "    fr = tit.result_global[k]\n",
    "    all_res = pd.concat([all_res, residual_frame(fr)])\n",
    "\n",
    "\n",
    "rows = []\n",
    "for well in tit.fit_keys:\n",
    "    fr = tit.result_global[well]\n",
    "    df = residual_frame(fr).assign(well=well)  # <-- add well id\n",
    "    rows.append(df)\n",
    "\n",
    "all_res = pd.concat(rows, ignore_index=True)\n",
    "all_res[\"x\"] = all_res[\"x\"].round(3)  # avoid float-key drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_col = \"resid_weighted\"  # or \"resid_weighted\"\n",
    "cov_by_label: dict[str, pd.DataFrame] = {}\n",
    "\n",
    "for lbl, g in all_res.groupby(\"label\"):\n",
    "    # rows = wells/curves, cols = x points\n",
    "    M = g.pivot_table(index=\"well\", columns=\"x\", values=val_col, aggfunc=\"mean\")\n",
    "    # drop wells missing any x (to make a clean covariance across x points)\n",
    "    M = M.dropna(axis=0, how=\"any\")\n",
    "\n",
    "    X = M.to_numpy(dtype=float)\n",
    "    # covariance across x-points (features), so rowvar=False\n",
    "    C = np.cov(X, rowvar=False, ddof=1)\n",
    "\n",
    "    cov_by_label[lbl] = pd.DataFrame(\n",
    "        C, index=M.columns.to_list(), columns=M.columns.to_list()\n",
    "    )\n",
    "\n",
    "# Example: covariance matrix for y2 (indexed by x values)\n",
    "cov_y2 = cov_by_label[\"y1\"]\n",
    "print(cov_y2.round(3))\n",
    "sns.heatmap(cov_y2.round(3), cmap=\"coolwarm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_by_label = {\n",
    "    lbl: cov / np.outer(np.sqrt(np.diag(cov)), np.sqrt(np.diag(cov)))\n",
    "    for lbl, cov in ((k, v.to_numpy()) for k, v in cov_by_label.items())\n",
    "}\n",
    "corr_y2 = pd.DataFrame(\n",
    "    corr_by_label[\"y2\"],\n",
    "    index=cov_by_label[\"y2\"].index,\n",
    "    columns=cov_by_label[\"y2\"].columns,\n",
    ")\n",
    "corr_y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(corr_y2, cmap=\"vlag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(all_res, x=\"x\", y=\"resid_weighted\", hue=\"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residues distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = \"G12\"\n",
    "\n",
    "fr1 = tit.results[1][k]\n",
    "fr1.figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr2 = tit.results[2][k]\n",
    "print(fr1.result.redchi, fr2.result.redchi)\n",
    "fr2.figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr2.result.residual * fr2.dataset[\"2\"].y_err / fr2.dataset[\"2\"].y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frg = tit.result_global[k]\n",
    "print(frg.result.redchi)\n",
    "frg.figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr1.dataset[\"1\"].y_err *= np.sqrt(fr1.result.redchi) / 2\n",
    "fr2.dataset[\"2\"].y_err *= np.sqrt(fr2.result.redchi) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr1.dataset[\"1\"].y_err, fr2.dataset[\"2\"].y_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frg.dataset[\"y1\"].y_err, frg.dataset[\"y2\"].y_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsg = deepcopy(frg.dataset)\n",
    "\n",
    "dsg[\"y1\"].y_errc = np.ones_like(dsg[\"y1\"].y_errc) * 44 * np.sqrt(9) / 3 * 3.1\n",
    "dsg[\"y2\"].y_errc = np.ones_like(dsg[\"y2\"].y_errc) * 14 * np.sqrt(9) / 3 * 3\n",
    "\n",
    "# weight_multi_ds_titration(dsg)\n",
    "dsg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr = fit_binding_glob(dsg)\n",
    "print(fr.result.redchi)\n",
    "fr.figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr.result.chisqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.abs(fr.result.residual[7:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clophfit.fitting.core import weight_da, weight_multi_ds_titration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_da(fr1.dataset[\"1\"], is_ph=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_multi_ds_titration(fr1.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_mcmc = tit.result_mcmc[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_mcmc.figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_odr = tit.result_odr[k]\n",
    "fr_odr.figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fr2.result.residual, \"o\")\n",
    "plt.plot(frg.result.residual, \"o\")\n",
    "plt.plot(fr_mcmc.result.residual, \"s\")\n",
    "plt.plot(fr_odr.result.residual, \"*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_odr.result.residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = tit.result_global\n",
    "tr[k].result.residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_df_all(tr) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for k in tr.fit_keys:\n",
    "        ds = tr[k].dataset\n",
    "        res = np.asarray(tr[k].result.residual, dtype=float)\n",
    "\n",
    "        start = 0\n",
    "        for label, da in ds.items():\n",
    "            x = np.asarray(da.x, dtype=float)  # masked x used in fit\n",
    "            n = x.size\n",
    "            r = res[start : start + n]\n",
    "            start += n\n",
    "            rows += [\n",
    "                {\"k\": k, \"label\": label, \"x\": float(xi), \"residue\": float(ri)}\n",
    "                for xi, ri in zip(x, r, strict=True)\n",
    "            ]\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "df = residual_df_all(tr)\n",
    "df[\"std_res\"] = (df.residue - np.nanmean(df.residue)) / np.nanstd(df.residue, ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.displot(\n",
    "    data=df,\n",
    "    x=\"std_res\",\n",
    "    col=\"label\",\n",
    "    kind=\"hist\",\n",
    "    bins=60,\n",
    "    stat=\"density\",\n",
    "    common_norm=False,\n",
    "    height=4,\n",
    "    aspect=1.2,\n",
    ")\n",
    "for ax in g.axes.flat:\n",
    "    sns.kdeplot(\n",
    "        data=df[df[\"label\"] == ax.get_title().split(\" = \")[-1]],\n",
    "        x=\"std_res\",\n",
    "        ax=ax,\n",
    "        lw=2,\n",
    "    )\n",
    "    ax.axvline(-2, ls=\"--\", c=\"crimson\", lw=1)\n",
    "    ax.axvline(2, ls=\"--\", c=\"crimson\", lw=1)\n",
    "    ax.set_xlim(-6, 6)\n",
    "g.set_titles(col_template=\"{col_name}\")\n",
    "g.fig.suptitle(\"Standardized residuals (with ±2σ)\", y=1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(\n",
    "    data=df,\n",
    "    x=\"x\",\n",
    "    y=\"std_res\",\n",
    "    col=\"label\",\n",
    "    kind=\"boxen\",  # nicer than boxplot for big n\n",
    "    showfliers=False,\n",
    "    height=4,\n",
    "    aspect=1.4,\n",
    "    sharey=True,\n",
    ")\n",
    "for ax in g.axes.flat:\n",
    "    ax.axhline(-2, ls=\"--\", c=\"crimson\", lw=1)\n",
    "    ax.axhline(2, ls=\"--\", c=\"crimson\", lw=1)\n",
    "    ax.set_xlabel(\"x\")\n",
    "    ax.set_ylabel(\"std_res\")\n",
    "    ax.tick_params(axis=\"x\", rotation=45)\n",
    "g.fig.suptitle(\"Std residuals vs x (per label)\", y=1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = (\n",
    "    df\n",
    "    .assign(out=np.abs(df[\"std_res\"]) > 2.5)\n",
    "    .groupby([\"k\", \"label\"], as_index=False)[\"out\"]\n",
    "    .mean()\n",
    "    .rename(columns={\"out\": \"outlier_rate\"})\n",
    ")\n",
    "# plot top offenders per label\n",
    "top = out.sort_values(\"outlier_rate\", ascending=False).groupby(\"label\").head(25)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(data=top, y=\"k\", x=\"outlier_rate\", hue=\"label\", dodge=False)\n",
    "plt.xlabel(\"Outlier rate (|std_res| > 2)\")\n",
    "plt.ylabel(\"k (top 25 per label)\")\n",
    "plt.title(\"Worst wells by standardized-residual outlier rate\")\n",
    "plt.legend(title=\"label\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[np.abs(df.std_res) > 2.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[np.abs(df.residue) > 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[np.abs(df.residue) > 2.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.std_res < -2.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.std_res < -2.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = tit.result_global\n",
    "\n",
    "residuals = [tr[k].result.residual.ravel() for k in tr.fit_keys]\n",
    "residuals = np.concatenate(residuals)\n",
    "\n",
    "all_res = residuals\n",
    "std_res = (all_res - np.nanmean(all_res)) / np.nanstd(all_res, ddof=1)\n",
    "std_res = residuals\n",
    "\n",
    "# stats\n",
    "k2, pval = stats.normaltest(std_res)\n",
    "skew = stats.skew(std_res, bias=False)\n",
    "kurt = stats.kurtosis(std_res, fisher=True, bias=False)\n",
    "\n",
    "# plot\n",
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "ax.hist(std_res, bins=40, density=True, color=\"#4c72b0\", alpha=0.7)\n",
    "x = np.linspace(-4, 4, 300)\n",
    "# ax.plot(x, stats.norm.pdf(x, 0, 1), \"r-\", lw=2, label=\"N(0,1) PDF\")\n",
    "ax.set_xlabel(\"Standardized residual\")\n",
    "ax.set_ylabel(\"Density\")\n",
    "ax.set_title(\"Residual distribution (all fits in tit.results[2])\")\n",
    "props = {\"boxstyle\": \"round\", \"facecolor\": \"white\", \"alpha\": 0.8}\n",
    "txt = f\"n={len(std_res)}\\n p={pval:.3g}\\n skew={skew:.3f}\\n kurt={kurt:.3f}\"\n",
    "ax.text(\n",
    "    0.98,\n",
    "    0.95,\n",
    "    txt,\n",
    "    transform=ax.transAxes,\n",
    "    fontsize=10,\n",
    "    va=\"top\",\n",
    "    ha=\"right\",\n",
    "    bbox=props,\n",
    ")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(std_res, kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.shapiro(std_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.kstest(std_res, \"norm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.probplot(std_res, plot=plt, rvalue=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seaborn doesn't have qqplot, use scipy.stats instead\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Histogram with KDE\n",
    "sns.histplot(std_res, kde=True, ax=ax1)\n",
    "\n",
    "# Q-Q plot (using scipy)\n",
    "stats.probplot(std_res, dist=\"norm\", plot=ax2)\n",
    "plt.show()\n",
    "# +end_src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tit.result_global[\"D03\"].figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(tit.result_odr[\"D03\"].result.residual, \"o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Discard detection\n",
    "\n",
    "test:\n",
    "\n",
    "- E10\n",
    "- F10\n",
    "- G09\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([np.nanmean(tit.data[1][k] / tit.data[2][k].mean()) for k in tit.fit_keys])\n",
    "\n",
    "print([\n",
    "    (t[0], t[1])\n",
    "    for t in [\n",
    "        (k, np.nanmean(tit.data[1][k] / tit.data[2][k].mean())) for k in tit.fit_keys\n",
    "    ]\n",
    "    if t[1] > 2 or t[1] < 1\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Synthetic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clophfit.testing.synthetic import (\n",
    "    _sample_correlated_signals,\n",
    "    _sample_from_real,\n",
    "    make_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from benchmarks.compare_fitting_methods import generate_synthetic_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = generate_synthetic_data(pKa=6.7, add_outliers=True)\n",
    "g = ds.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[\"y1\"].y_err / ds[\"y1\"].y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds, truth = make_dataset(\n",
    "    7, randomize_signals=1, error_model=\"realistic\", rel_error={\"y1\": 0.100, \"y2\": 0.2}\n",
    ")  # uniform simple realistic physics\n",
    "g = ds.plot()\n",
    "print(truth)\n",
    "fr = outlier2(ds)\n",
    "fr.figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = generate_synthetic_data(pKa=6.7, add_outliers=True)\n",
    "fr = outlier2(ds, error_model=\"uniform\")\n",
    "fr.figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds, thruth = make_dataset(\n",
    "    7.0, 2000, 200, is_ph=True, n_labels=1, error_model=\"realistic\"\n",
    ")\n",
    "fr = outlier2(ds)\n",
    "# fr.figure\n",
    "plt.plot(ds[\"y0\"].x, fr.result.residual / ds[\"y0\"].y, \"o-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    ds[\"y0\"].y_err / ds[\"y0\"].y,\n",
    "    fr.result.residual * fr.dataset[\"y0\"].y_err / fr.dataset[\"y0\"].y,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ks = []\n",
    "sKs = []\n",
    "for _i in range(99):\n",
    "    ds = generate_synthetic_data(7.1, add_outliers=True)\n",
    "    fr = outlier2(ds, error_model=\"uniform\")\n",
    "    Ks.append(fr.result.params[\"K\"].value)\n",
    "    sKs.append(fr.result.params[\"K\"].stderr)\n",
    "sns.histplot(Ks, kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\"K\": Ks, \"K_err\": sKs})\n",
    "df = df[df.K_err < 0.5]\n",
    "\n",
    "plt.errorbar(x=range(len(df.K)), y=df.K, yerr=df.K_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6), sharey=True, width_ratios=[3, 1])\n",
    "\n",
    "# Left panel\n",
    "ax1.errorbar(\n",
    "    x=range(len(df.K)),\n",
    "    y=df.K,\n",
    "    yerr=df.K_err,\n",
    "    fmt=\"o\",\n",
    "    capsize=3,\n",
    "    alpha=0.7,\n",
    "    label=\"K ± error\",\n",
    ")\n",
    "ax1.axhline(\n",
    "    y=df.K.mean(),\n",
    "    color=\"r\",\n",
    "    linestyle=\"--\",\n",
    "    alpha=0.7,\n",
    "    label=f\"Mean: {df.K.mean():.2f}\",\n",
    ")\n",
    "ax1.set_xlabel(\"Index\")\n",
    "ax1.set_ylabel(\"K\")\n",
    "ax1.set_title(f\"K values (n={len(df.K)})\")\n",
    "ax1.legend()\n",
    "ax1.grid(alpha=0.3)\n",
    "\n",
    "# Right panel with both histogram and KDE\n",
    "ax2_hist = ax2\n",
    "ax2_kde = ax2.twinx()\n",
    "\n",
    "# Histogram\n",
    "n, bins, patches = ax2_hist.hist(\n",
    "    df.K, bins=30, orientation=\"horizontal\", alpha=0.3, edgecolor=\"black\", density=False\n",
    ")\n",
    "\n",
    "# KDE\n",
    "kde = stats.gaussian_kde(df.K)\n",
    "x_kde = np.linspace(df.K.min(), df.K.max(), 200)\n",
    "y_kde = kde(x_kde)\n",
    "# Scale KDE to match histogram visually\n",
    "scale_factor = n.max() / y_kde.max()\n",
    "ax2_kde.plot(y_kde * scale_factor, x_kde, \"r-\", linewidth=2, alpha=0.7, label=\"KDE\")\n",
    "\n",
    "ax2_hist.set_xlabel(\"Frequency\")\n",
    "ax2_kde.set_xlabel(\"Density (scaled)\", color=\"r\")\n",
    "ax2_hist.set_title(\"Distribution\")\n",
    "ax2_hist.tick_params(axis=\"x\")\n",
    "ax2_kde.tick_params(axis=\"x\", labelcolor=\"r\")\n",
    "ax2_hist.grid(alpha=0.3)\n",
    "\n",
    "# Add statistics text box\n",
    "stats_text = f\"Mean: {df.K.mean():.3f}\\nStd: {df.K.std():.3f}\\nMin: {df.K.min():.3f}\\nMax: {df.K.max():.3f}\"\n",
    "ax2_hist.text(\n",
    "    0.7,\n",
    "    0.95,\n",
    "    stats_text,\n",
    "    transform=ax2_hist.transAxes,\n",
    "    fontsize=10,\n",
    "    verticalalignment=\"top\",\n",
    "    bbox={\"boxstyle\": \"round\", \"facecolor\": \"wheat\", \"alpha\": 0.8},\n",
    ")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(Ks), np.median(Ks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(None)\n",
    "\n",
    "_sample_from_real(rng, \"K\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_sample_correlated_signals(rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "rel_error = {\"y1\": 0.04, \"y2\": 0.01}\n",
    "make_ds = partial(\n",
    "    make_dataset,\n",
    "    randomize_signals=True,\n",
    "    rel_error=rel_error,\n",
    "    min_error=1,\n",
    "    low_ph_drop=False,\n",
    "    x_error_large=0.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "values = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds, truth = make_dataset(6.8, randomize_signals=True, error_model=\"physics\", noise=.01, rel_error=rel_error, outlier_prob=.1, outlier_sigma=4)\n",
    "# ds, truth = make_dataset(6.8, randomize_signals=True, rel_error=rel_error, min_error=1, low_ph_drop=True, low_ph_drop_magnitude=.25, low_ph_drop6_prob=.0, x_error_large=0.0, seed=1)\n",
    "ds, truth = make_ds(6.8)\n",
    "g = ds.plot()\n",
    "\n",
    "fr = outlier2(ds, error_model=\"uniform\")\n",
    "fr.figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _i in range(33):\n",
    "    ds, truth = make_ds(7.2, min_error=0.1)\n",
    "\n",
    "    fr = fit_binding_glob_reweighted(ds, \"\")\n",
    "    values[\"reweighted\"].append(fr.result.params[\"K\"].value)\n",
    "    fr = fit_binding_glob_recursive_outlier(ds)\n",
    "    values[\"recursive_outlier\"].append(fr.result.params[\"K\"].value)\n",
    "    fr = outlier2(ds)\n",
    "    values[\"outlier\"].append(fr.result.params[\"K\"].value)\n",
    "    # fr = fit_binding_pymc2(ds)\n",
    "    fr = fit_binding_odr(ds)\n",
    "    values[\"odr\"].append(fr.result.params[\"K\"].value)\n",
    "\n",
    "for key in values:\n",
    "    print(key, np.median(values[key]), np.mean(values[key]))\n",
    "\n",
    "sns.histplot(values, kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.stripplot(values)\n",
    "sns.boxplot(values, saturation=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = \"B04\"\n",
    "\n",
    "ds = tit._create_global_ds(k)\n",
    "ds[\"y1\"].y_err.mean(), ds[\"y2\"].y_err.mean()\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = fit_binding_glob(ds)\n",
    "r2 = fit_binding_glob(ds, robust=True)\n",
    "r3 = fit_binding_glob_reweighted(ds, k, threshold=2.5)\n",
    "r4 = fit_binding_glob_recursive(ds, tol=0.001, max_iterations=100)\n",
    "r5 = fit_binding_glob_recursive_outlier(ds, tol=0.001, threshold=2)\n",
    "r6 = outlier2(ds, k, threshold=3, plot_z_scores=True)\n",
    "r7 = outlier2(ds, k, threshold=3, plot_z_scores=True, error_model=\"shot-noise\")\n",
    "\n",
    "r8 = fit_binding_odr(r1)\n",
    "r9 = fit_binding_odr_recursive(r1, tol=0.001, max_iterations=100)\n",
    "r10 = fit_binding_odr_recursive_outlier(r1, tol=0.001, threshold=3)\n",
    "\n",
    "fr = r2\n",
    "n_sd = 0.15 / fr.result.params[\"K\"].stderr\n",
    "print(n_sd)\n",
    "r11 = fit_binding_pymc(fr, n_sd=max(n_sd, 1), n_xerr=0.682, ye_scaling=10)\n",
    "r12 = fit_binding_pymc2(fr, n_sd=max(n_sd, 1), n_xerr=0.682)\n",
    "\n",
    "buffer_sd = {\"y1\": fr.dataset[\"y1\"].y_err.mean(), \"y2\": fr.dataset[\"y2\"].y_err.mean()}\n",
    "buffer_sd = {\"y1\": tit.bg_err[1].mean(), \"y2\": tit.bg_err[2].mean()}\n",
    "print(buffer_sd)\n",
    "trace_compare = fit_binding_pymc_compare(\n",
    "    fr, buffer_sd=buffer_sd, learn_separate_y_mag=True, n_sd=max(n_sd, 1), n_xerr=0.682\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\"y1\": tit.bg_err[1].mean(), \"y2\": tit.bg_err[2].mean()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[\"y1\"].y_err, ds[\"y2\"].y_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r7.dataset[\"y2\"].y_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1.result.chisqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r12.figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(trace_compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine log likelihoods for multi-output models before comparison\n",
    "import warnings\n",
    "\n",
    "import xarray as xr\n",
    "\n",
    "\n",
    "def combine_log_likelihoods(idata):\n",
    "    \"\"\"Concatenate log likelihoods across all likelihood variables.\"\"\"\n",
    "    if not hasattr(idata, \"log_likelihood\"):\n",
    "        return idata\n",
    "    ll = idata.log_likelihood\n",
    "    # Concatenate all likelihood variables along observation dimension\n",
    "    arrays = [ll[var].rename({list(ll[var].dims)[-1]: \"obs\"}) for var in ll.data_vars]\n",
    "    combined = xr.concat(arrays, dim=\"obs\")\n",
    "    new_ll = xr.Dataset({\"combined\": combined})\n",
    "    return az.InferenceData(posterior=idata.posterior, log_likelihood=new_ll)\n",
    "\n",
    "\n",
    "# Combine log likelihoods and compare (suppress Pareto-k warnings)\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", message=\"Estimated shape parameter of Pareto\")\n",
    "    comparison_results = az.compare({\n",
    "        \"single_y_mag\": combine_log_likelihoods(r11.mini),\n",
    "        \"separate_y_mag\": combine_log_likelihoods(r12.mini),\n",
    "        \"separate_y_mag_bg\": combine_log_likelihoods(trace_compare),\n",
    "    })\n",
    "\n",
    "# The result is a pandas DataFrame.\n",
    "# The best model has the lowest 'loo' or 'waic' value.\n",
    "# The 'd_loo' column shows the difference from the best model.\n",
    "# Note: warning=True in results indicates some Pareto-k > 0.7 (influential observations)\n",
    "comparison_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds2 = tit._create_ds(k, 2)\n",
    "outlier2(ds2, error_model=\"shot-noise\").figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
