{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Tips for development vs tutorial hygiene:\n",
    "---\n",
    "- Keep a scratch notebook (e.g., `prtecan_devel.ipynb`) for experiments.\n",
    "- Avoid `os.chdir`; use Path objects relative to repository root as in this notebook.\n",
    "- When a feature stabilizes, port minimal, clear examples into the main tutorial and keep heavy testing in `tests/`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Magic commands for development\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from clophfit import prtecan\n",
    "from clophfit.fitting.bayes import (\n",
    "    fit_binding_pymc,\n",
    "    fit_binding_pymc2,\n",
    "    fit_binding_pymc_compare,\n",
    ")\n",
    "from clophfit.fitting.core import (\n",
    "    fit_binding_glob,\n",
    "    fit_binding_glob_recursive,\n",
    "    fit_binding_glob_recursive_outlier,\n",
    "    fit_binding_glob_reweighted,\n",
    "    outlier2,\n",
    ")\n",
    "from clophfit.fitting.odr import (\n",
    "    fit_binding_odr,\n",
    "    fit_binding_odr_recursive,\n",
    "    fit_binding_odr_recursive_outlier,\n",
    ")\n",
    "\n",
    "# Configure notebook\n",
    "%matplotlib inline\n",
    "plt.style.use(\"seaborn-v0_8\")\n",
    "\n",
    "data_root = Path(\"tests/Tecan\")\n",
    "l0_dir = data_root / \"140220\"\n",
    "l1_dir = data_root / \"L1\"\n",
    "l2_dir = data_root / \"L2\"\n",
    "l4_dir = data_root / \"L4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tit(folder, bg_mth=\"meansd\"):\n",
    "    tit = prtecan.Titration.fromlistfile(folder / \"list.pH.csv\", is_ph=1)\n",
    "    tit.load_additions(folder / \"additions.pH\")\n",
    "    tit.load_scheme(folder / \"scheme.txt\")\n",
    "    tit.params.bg_mth = bg_mth\n",
    "    tit.params.bg_adj = True\n",
    "    return tit\n",
    "\n",
    "\n",
    "tit = tit(l2_dir)\n",
    "tit.bg_err"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from clophfit.fitting.core import fit_binding_pymc_multi2\n",
    "\n",
    "trace = fit_binding_pymc_multi2(\n",
    "    tit.result_global.results, tit.scheme, tit.buffer.bg_err\n",
    ")\n",
    "\n",
    "df = az.summary(trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Discard detection\n",
    "\n",
    "test:\n",
    "\n",
    "- E10\n",
    "- F10\n",
    "- G09\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([np.nanmean(tit.data[1][k] / tit.data[2][k].mean()) for k in tit.fit_keys])\n",
    "\n",
    "print([\n",
    "    (t[0], t[1])\n",
    "    for t in [\n",
    "        (k, np.nanmean(tit.data[1][k] / tit.data[2][k].mean())) for k in tit.fit_keys\n",
    "    ]\n",
    "    if t[1] > 2 or t[1] < 1\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "from clophfit.testing.synthetic import (\n",
    "    _sample_correlated_signals,\n",
    "    _sample_from_real,\n",
    "    make_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(None)\n",
    "\n",
    "_sample_from_real(rng, \"K\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_sample_correlated_signals(rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "rel_error = {\"y1\": 0.04, \"y2\": 0.01}\n",
    "make_ds = partial(\n",
    "    make_dataset,\n",
    "    randomize_signals=True,\n",
    "    rel_error=rel_error,\n",
    "    min_error=1,\n",
    "    low_ph_drop=False,\n",
    "    low_ph_drop_magnitude=0.25,\n",
    "    low_ph_drop6_prob=0.0,\n",
    "    x_error_large=0.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "values = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds, truth = make_dataset(6.8, randomize_signals=True, error_model=\"physics\", noise=.01, rel_error=rel_error, outlier_prob=.1, outlier_sigma=4)\n",
    "# ds, truth = make_dataset(6.8, randomize_signals=True, rel_error=rel_error, min_error=1, low_ph_drop=True, low_ph_drop_magnitude=.25, low_ph_drop6_prob=.0, x_error_large=0.0, seed=1)\n",
    "ds, truth = make_ds(6.8)\n",
    "g = ds.plot()\n",
    "\n",
    "fr = outlier2(ds, error_model=\"uniform\")\n",
    "fr.figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _i in range(33):\n",
    "    ds, truth = make_ds(7.2, min_error=0.1)\n",
    "\n",
    "    fr = fit_binding_glob_reweighted(ds, \"\")\n",
    "    values[\"reweighted\"].append(fr.result.params[\"K\"].value)\n",
    "    fr = fit_binding_glob_recursive_outlier(ds)\n",
    "    values[\"recursive_outlier\"].append(fr.result.params[\"K\"].value)\n",
    "    fr = outlier2(ds)\n",
    "    values[\"outlier\"].append(fr.result.params[\"K\"].value)\n",
    "    # fr = fit_binding_pymc2(ds)\n",
    "    fr = fit_binding_odr(ds)\n",
    "    values[\"odr\"].append(fr.result.params[\"K\"].value)\n",
    "\n",
    "for key in values:\n",
    "    print(key, np.median(values[key]), np.mean(values[key]))\n",
    "\n",
    "sns.histplot(values, kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.stripplot(values)\n",
    "sns.boxplot(values, saturation=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = \"B04\"\n",
    "\n",
    "ds = tit._create_global_ds(k)\n",
    "ds[\"y1\"].y_err.mean(), ds[\"y2\"].y_err.mean()\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = fit_binding_glob(ds)\n",
    "r2 = fit_binding_glob(ds, robust=True)\n",
    "r3 = fit_binding_glob_reweighted(ds, k, threshold=2.5)\n",
    "r4 = fit_binding_glob_recursive(ds, tol=0.001, max_iterations=100)\n",
    "r5 = fit_binding_glob_recursive_outlier(ds, tol=0.001, threshold=2)\n",
    "r6 = outlier2(ds, k, threshold=3, plot_z_scores=True)\n",
    "r7 = outlier2(ds, k, threshold=3, plot_z_scores=True, error_model=\"shot-noise\")\n",
    "\n",
    "r8 = fit_binding_odr(r1)\n",
    "r9 = fit_binding_odr_recursive(r1, tol=0.001, max_iterations=100)\n",
    "r10 = fit_binding_odr_recursive_outlier(r1, tol=0.001, threshold=3)\n",
    "\n",
    "fr = r2\n",
    "n_sd = 0.15 / fr.result.params[\"K\"].stderr\n",
    "print(n_sd)\n",
    "r11 = fit_binding_pymc(fr, n_sd=max(n_sd, 1), n_xerr=0.682, ye_scaling=10)\n",
    "r12 = fit_binding_pymc2(fr, n_sd=max(n_sd, 1), n_xerr=0.682)\n",
    "\n",
    "buffer_sd = {\"y1\": fr.dataset[\"y1\"].y_err.mean(), \"y2\": fr.dataset[\"y2\"].y_err.mean()}\n",
    "buffer_sd = {\"y1\": tit.bg_err[1].mean(), \"y2\": tit.bg_err[2].mean()}\n",
    "print(buffer_sd)\n",
    "trace_compare = fit_binding_pymc_compare(\n",
    "    fr, buffer_sd=buffer_sd, learn_separate_y_mag=True, n_sd=max(n_sd, 1), n_xerr=0.682\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\"y1\": tit.bg_err[1].mean(), \"y2\": tit.bg_err[2].mean()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[\"y1\"].y_err, ds[\"y2\"].y_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r7.dataset[\"y2\"].y_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1.result.chisqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r12.figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(trace_compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine log likelihoods for multi-output models before comparison\n",
    "import warnings\n",
    "\n",
    "import xarray as xr\n",
    "\n",
    "\n",
    "def combine_log_likelihoods(idata):\n",
    "    \"\"\"Concatenate log likelihoods across all likelihood variables.\"\"\"\n",
    "    if not hasattr(idata, \"log_likelihood\"):\n",
    "        return idata\n",
    "    ll = idata.log_likelihood\n",
    "    # Concatenate all likelihood variables along observation dimension\n",
    "    arrays = [ll[var].rename({list(ll[var].dims)[-1]: \"obs\"}) for var in ll.data_vars]\n",
    "    combined = xr.concat(arrays, dim=\"obs\")\n",
    "    new_ll = xr.Dataset({\"combined\": combined})\n",
    "    return az.InferenceData(posterior=idata.posterior, log_likelihood=new_ll)\n",
    "\n",
    "\n",
    "# Combine log likelihoods and compare (suppress Pareto-k warnings)\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", message=\"Estimated shape parameter of Pareto\")\n",
    "    comparison_results = az.compare({\n",
    "        \"single_y_mag\": combine_log_likelihoods(r11.mini),\n",
    "        \"separate_y_mag\": combine_log_likelihoods(r12.mini),\n",
    "        \"separate_y_mag_bg\": combine_log_likelihoods(trace_compare),\n",
    "    })\n",
    "\n",
    "# The result is a pandas DataFrame.\n",
    "# The best model has the lowest 'loo' or 'waic' value.\n",
    "# The 'd_loo' column shows the difference from the best model.\n",
    "# Note: warning=True in results indicates some Pareto-k > 0.7 (influential observations)\n",
    "comparison_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds2 = tit._create_ds(k, 2)\n",
    "outlier2(ds2, error_model=\"shot-noise\").figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
