{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting Method Comparison: GLS vs PyMC\n",
    "\n",
    "**Goal:** Compare Generalized Least Squares (GLS) and PyMC approaches on synthetic and real data.\n",
    "\n",
    "**Methods Compared:**\n",
    "1. **GLS with covariance structure** - Use characterized noise covariance\n",
    "2. **PyMC with hierarchical error model** - Let hierarchical model learn error structure\n",
    "3. **PyMC with correlated residuals** - Explicitly model correlation structure\n",
    "\n",
    "**Evaluation:**\n",
    "- **Synthetic data:** Parameter recovery (bias, RMSE, coverage)\n",
    "- **Real data:** Residual patterns, diagnostic plots\n",
    "- **Practical:** Computational cost, ease of use, robustness\n",
    "\n",
    "**Outputs:**\n",
    "- Performance comparison tables\n",
    "- Method recommendation\n",
    "- Diagnostic plots\n",
    "\n",
    "**Next:** Update main fitting pipeline with best approach\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Tips for development vs tutorial hygiene:\n",
    "---\n",
    "- Keep a scratch notebook (e.g., `prtecan_devel.ipynb`) for experiments.\n",
    "- Avoid `os.chdir`; use Path objects relative to repository root as in this notebook.\n",
    "- When a feature stabilizes, port minimal, clear examples into the main tutorial and keep heavy testing in `tests/`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Magic commands for development\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from clophfit import prtecan\n",
    "from clophfit.fitting.bayes import (\n",
    "    fit_binding_pymc,\n",
    "    fit_binding_pymc2,\n",
    "    fit_binding_pymc_compare,\n",
    ")\n",
    "from clophfit.fitting.core import (\n",
    "    fit_binding_glob,\n",
    "    fit_binding_glob_recursive,\n",
    "    fit_binding_glob_recursive_outlier,\n",
    "    fit_binding_glob_reweighted,\n",
    "    outlier2,\n",
    ")\n",
    "from clophfit.fitting.odr import (\n",
    "    fit_binding_odr,\n",
    "    fit_binding_odr_recursive,\n",
    "    fit_binding_odr_recursive_outlier,\n",
    ")\n",
    "\n",
    "# Configure notebook\n",
    "%matplotlib inline\n",
    "plt.style.use(\"seaborn-v0_8\")\n",
    "\n",
    "data_root = Path(\"tests/Tecan\")\n",
    "l0_dir = data_root / \"140220\"\n",
    "l1_dir = data_root / \"L1\"\n",
    "l2_dir = data_root / \"L2\"\n",
    "l4_dir = data_root / \"L4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tit(folder, bg_mth=\"meansd\"):\n",
    "    tit = prtecan.Titration.fromlistfile(folder / \"list.pH.csv\", is_ph=1)\n",
    "    tit.load_additions(folder / \"additions.pH\")\n",
    "    tit.load_scheme(folder / \"scheme.txt\")\n",
    "    tit.params.bg_mth = bg_mth\n",
    "    tit.params.bg_adj = True\n",
    "    return tit\n",
    "\n",
    "\n",
    "tit = tit(l2_dir)\n",
    "tit.bg_err"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from clophfit.fitting.core import fit_binding_pymc_multi2\n",
    "\n",
    "trace = fit_binding_pymc_multi2(\n",
    "    tit.result_global.results, tit.scheme, tit.buffer.bg_err\n",
    ")\n",
    "\n",
    "df = az.summary(trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1: GLS with Covariance Structure\n",
    "\n",
    "Implement generalized least squares using characterized covariance matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement GLS with covariance\n",
    "# Load covariance matrices from dev/\n",
    "# Apply to fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2: PyMC with Hierarchical Error Model\n",
    "\n",
    "Use existing PyMC implementation with hierarchical error structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Comparison\n",
    "\n",
    "Compare methods on synthetic data with known ground truth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = \"B04\"\n",
    "\n",
    "ds = tit._create_global_ds(k)\n",
    "ds[\"y1\"].y_err.mean(), ds[\"y2\"].y_err.mean()\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = fit_binding_glob(ds)\n",
    "r2 = fit_binding_glob(ds, robust=True)\n",
    "r3 = fit_binding_glob_reweighted(ds, k, threshold=2.5)\n",
    "r4 = fit_binding_glob_recursive(ds, tol=0.001, max_iterations=100)\n",
    "r5 = fit_binding_glob_recursive_outlier(ds, tol=0.001, threshold=2)\n",
    "r6 = outlier2(ds, k, threshold=3, plot_z_scores=True)\n",
    "r7 = outlier2(ds, k, threshold=3, plot_z_scores=True, error_model=\"shot-noise\")\n",
    "\n",
    "r8 = fit_binding_odr(r1)\n",
    "r9 = fit_binding_odr_recursive(r1, tol=0.001, max_iterations=100)\n",
    "r10 = fit_binding_odr_recursive_outlier(r1, tol=0.001, threshold=3)\n",
    "\n",
    "fr = r2\n",
    "n_sd = 0.15 / fr.result.params[\"K\"].stderr\n",
    "print(n_sd)\n",
    "r11 = fit_binding_pymc(fr, n_sd=max(n_sd, 1), n_xerr=0.682, ye_scaling=10)\n",
    "r12 = fit_binding_pymc2(fr, n_sd=max(n_sd, 1), n_xerr=0.682)\n",
    "\n",
    "buffer_sd = {\"y1\": fr.dataset[\"y1\"].y_err.mean(), \"y2\": fr.dataset[\"y2\"].y_err.mean()}\n",
    "buffer_sd = {\"y1\": tit.bg_err[1].mean(), \"y2\": tit.bg_err[2].mean()}\n",
    "print(buffer_sd)\n",
    "trace_compare = fit_binding_pymc_compare(\n",
    "    fr, buffer_sd=buffer_sd, learn_separate_y_mag=True, n_sd=max(n_sd, 1), n_xerr=0.682\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\"y1\": tit.bg_err[1].mean(), \"y2\": tit.bg_err[2].mean()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[\"y1\"].y_err, ds[\"y2\"].y_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r7.dataset[\"y2\"].y_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1.result.chisqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r12.figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(trace_compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine log likelihoods for multi-output models before comparison\n",
    "import warnings\n",
    "\n",
    "import xarray as xr\n",
    "\n",
    "\n",
    "def combine_log_likelihoods(idata):\n",
    "    \"\"\"Concatenate log likelihoods across all likelihood variables.\"\"\"\n",
    "    if not hasattr(idata, \"log_likelihood\"):\n",
    "        return idata\n",
    "    ll = idata.log_likelihood\n",
    "    # Concatenate all likelihood variables along observation dimension\n",
    "    arrays = [ll[var].rename({list(ll[var].dims)[-1]: \"obs\"}) for var in ll.data_vars]\n",
    "    combined = xr.concat(arrays, dim=\"obs\")\n",
    "    new_ll = xr.Dataset({\"combined\": combined})\n",
    "    return az.InferenceData(posterior=idata.posterior, log_likelihood=new_ll)\n",
    "\n",
    "\n",
    "# Combine log likelihoods and compare (suppress Pareto-k warnings)\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", message=\"Estimated shape parameter of Pareto\")\n",
    "    comparison_results = az.compare({\n",
    "        \"single_y_mag\": combine_log_likelihoods(r11.mini),\n",
    "        \"separate_y_mag\": combine_log_likelihoods(r12.mini),\n",
    "        \"separate_y_mag_bg\": combine_log_likelihoods(trace_compare),\n",
    "    })\n",
    "\n",
    "# The result is a pandas DataFrame.\n",
    "# The best model has the lowest 'loo' or 'waic' value.\n",
    "# The 'd_loo' column shows the difference from the best model.\n",
    "# Note: warning=True in results indicates some Pareto-k > 0.7 (influential observations)\n",
    "comparison_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds2 = tit._create_ds(k, 2)\n",
    "outlier2(ds2, error_model=\"shot-noise\").figure"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
